
warning off %#ok<WNOFF>
clear all
clc

addpath(genpath('.'));
starttime = datestr(now,0);


load 'data/emotion.mat';

train_target(train_target==-1)=0;
test_target(test_target==-1)=0;

%% Optimization Parameters
model_MLL.type=0;               
optmParameter.alpha   = 2^-1; % 2.^[-10:10]
optmParameter.beta    = 2^-1; % 2.^[-10:10] 
optmParameter.lambda  = 2^-1; % 2.^[-10:10]
optmParameter.theta   = 2^-1; % 2.^[-10:10] 
optmParameter.theta1   = 2^-1; % 2.^[-10:10] 
optmParameter.gamma   = 1; %{0.1, 1, 10} 


optmParameter.tuneParaOneTime = 1; 



    
optmParameter.maxIter           = 100;
optmParameter.minimumLossMargin = 0.0001;
optmParameter.bQuiet             = 1;

%% Model Parameters
modelparameter.crossvalidation    = 1; % {0,1}
modelparameter.cv_num             = 5;
modelparameter.L2Norm             = 1; % {0,1}
modelparameter.drawNumofFeatures  = 0; % {0,1}
modelparameter.deleteData         = 1; % {0,1}

%% Train and Test
if modelparameter.crossvalidation==0 
else
%% cross validation
    if exist('train_data','var')==1
        data=[train_data;test_data];
        target=[train_target,test_target];
        clear train_data test_data train_target test_target
    end
    data     = double(data);
    num_data = size(data,1);
    if modelparameter.L2Norm == 1
        temp_data = data;
        temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
        if sum(sum(isnan(temp_data)))>0
            temp_data = data+eps;
            temp_data = temp_data./repmat(sqrt(sum(temp_data.^2,2)),1,size(temp_data,2));
        end
    else
        temp_data = data;
    end
    if modelparameter.deleteData
        clear data
    end
    
    randorder = randperm(num_data);
    Result_LLSF  = zeros(16,modelparameter.cv_num);

    for j = 1:modelparameter.cv_num
        fprintf('Running Fold - %d/%d \n',j,modelparameter.cv_num);

       %% the training and test parts are generated by fixed spliting with the given random order
        [cv_train_data,cv_train_target,cv_test_data,cv_test_target ] = generateCVSet( temp_data,target',randorder,j,modelparameter.cv_num );
        cv_train_target=cv_train_target';
        cv_test_target=cv_test_target';

       
        
       %% If we don't search the parameters, we will run MLDL with the fixed parametrs
        [model_MLDL,loss]  = MLDL(cv_train_data, cv_train_target',optmParameter);
        [Pre_Labels,Outputs]=LabelSpecificFeature(cv_test_data,cv_test_target,cv_train_data,cv_train_target,model_MLDL,model_MLL);
        

        
       %% evaluation of MLDL
        Result_LLSF(:,j) = EvaluationAll(Pre_Labels,Outputs',cv_test_target);

       %% count the number of label specific features for each label
       
    end

   %% the average results of LLSF
    Avg_Result = zeros(16,2);
    Avg_Result(:,1)=mean(Result_LLSF,2);
    Avg_Result(:,2)=std(Result_LLSF,1,2);
    fprintf('\nResults of LLSF\n');
    PrintResults(Avg_Result);

end
endtime = datestr(now,0);





